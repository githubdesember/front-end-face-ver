{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python imgbeddings psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mkuliah\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFC/facefolder/testing.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[0;32m      6\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(file, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m gray_img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_RGB2BGR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m faces \u001b[38;5;241m=\u001b[39m haar_cascade\u001b[38;5;241m.\u001b[39mdetectMultiScale(gray_img, scaleFactor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.05\u001b[39m, minNeighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, minSize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m)) \u001b[38;5;66;03m#adjust accordingly\u001b[39;00m\n\u001b[0;32m     10\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "#algoritma\n",
    "alg = \"haarcascade_frontalface_default.xml\"\n",
    "haar_cascade = cv2.CascadeClassifier(alg) #pass alg to opencv\n",
    "file = 'D:\\kuliah\\FC/facefolder/testing.jpg' \n",
    "img = cv2.imread(file, 0)\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "faces = haar_cascade.detectMultiScale(gray_img, scaleFactor=1.05, minNeighbors=5, minSize=(100, 100)) #adjust accordingly\n",
    "\n",
    "i = 0\n",
    "# for each face detected\n",
    "for x, y, w, h in faces:\n",
    "    # crop the image to select only the face\n",
    "    cropped_image = img[y : y + h, x : x + w]\n",
    "    # loading the target image path into target_file_name variable  - replace <INSERT YOUR TARGET IMAGE NAME HERE> with the path to your target image\n",
    "    target_file_name = 'stored-faces/' + str(i) + '.jpg'\n",
    "    cv2.imwrite(\n",
    "        target_file_name,\n",
    "        cropped_image,\n",
    "    )\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'face_recognition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpy\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mface_recognition\u001b[39;00m\n\u001b[0;32m      7\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      9\u001b[0m cap\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m640\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'face_recognition'"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import pickle\n",
    "import numpy as py\n",
    "import os\n",
    "import face_recognition\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "imgBackground = cv.imread('resource/background.png')\n",
    "\n",
    "folderMode = 'images'\n",
    "modePath = os.listdir(folderMode)\n",
    "imgModeList = []\n",
    "for path in modePath:\n",
    "    imgModeList.append(cv.imread(os.path.join(folderMode, path)))\n",
    "# print(len(imgModeList))\n",
    "\n",
    "#load encoder\n",
    "print(\"loading encoder\")\n",
    "file = open('encodefile.p', 'rb')s\n",
    "knownEncodeID = pickle.load(file)\n",
    "file.close()\n",
    "knownEncode, stdID = knownEncodeID\n",
    "# print(stdID)\n",
    "print(\"encoder loaded\")\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    imgS = cv.resize(img,(0, 0), None, 0.25, 0.25,)\n",
    "    imgS = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    \n",
    "    faceCF = face_recognition.face_locations(imgS)\n",
    "    encodeCF = face_recognition.face_encodings(imgS, faceCF)\n",
    "    print(faceCF)\n",
    "    print(encodeCF)    \n",
    "    \n",
    "    imgBackground[162:162+480, 55:55+640] = img\n",
    "    imgBackground[44:44+633, 808:808+414] = imgModeList[3]\n",
    "        \n",
    "    for encodeFace, faceLoc in zip(encodeCF, faceCF):\n",
    "        match = face_recognition.compare_faces(knownEncode, encodeFace)\n",
    "        faceDis = face_recognition.face_distance(knownEncode, encodeFace)\n",
    "        print('Loop iteration executed')\n",
    "    #     print('matches:', match)\n",
    "    #     print('faceDis:', faceDis)\n",
    "\n",
    "\n",
    "\n",
    "    # cv.imshow(\"webcam\", img)\n",
    "    cv.imshow(\"face attendance\", imgBackground)\n",
    "    \n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break \n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import cvzone as cvz\n",
    "import face_recognition\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "cap.set(cv.CAP_PROP_FPS, 30)\n",
    "\n",
    "imgBackground = cv.imread('resource/background.png')\n",
    "\n",
    "folderMode = 'resource/Modes'\n",
    "modePath = os.listdir(folderMode)\n",
    "imgModeList = []\n",
    "for path in modePath:\n",
    "    imgModeList.append(cv.imread(os.path.join(folderMode, path)))\n",
    "# print(len(imgModeList))\n",
    "\n",
    "#load encoder\n",
    "print(\"loading encoder\")\n",
    "file = open('encodefile.p', 'rb')\n",
    "knownEncodeID = pickle.load(file)\n",
    "file.close()\n",
    "knownEncode, stdID = knownEncodeID\n",
    "# print(stdID)\n",
    "print(\"encoder loaded\")\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    imgS = cv.resize(img,(0, 0), None, 0.25, 0.25,)\n",
    "    imgS = cv.cvtColor(imgS, cv.COLOR_BGR2RGB)\n",
    "    \n",
    "    faceCF = face_recognition.face_locations(imgS)\n",
    "    encodeCF = face_recognition.face_encodings(imgS, faceCF)\n",
    "    # print(faceCF)\n",
    "    # print(encodeCF)    \n",
    "    \n",
    "    imgBackground[162:162+480, 55:55+640] = img\n",
    "    imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[3]\n",
    "        \n",
    "    for encodeFace, faceLoc in zip(encodeCF, faceCF):\n",
    "        match = face_recognition.compare_faces(knownEncode, encodeFace)\n",
    "        faceDis = face_recognition.face_distance(knownEncode, encodeFace)\n",
    "        # print('Loop iteration executed')\n",
    "        # print('matches:', match)\n",
    "        # print('faceDis:', faceDis)\n",
    "\n",
    "    matchIndex = np.argmin(faceDis)\n",
    "    # print(\"match index : \", matchIndex)\n",
    "    \n",
    "    if match[matchIndex]:\n",
    "        print(\"Known Face Detected\")\n",
    "        print(stdID[matchIndex])\n",
    "        y1, x2, y2, x1 = faceLoc\n",
    "        y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "        bbox = 55 + x1, 162 + y1, x2 - x1, y2 - y1\n",
    "        \n",
    "        imgBackground = cvz.cornerRect(imgBackground, bbox, rt=0)\n",
    "    # cv.imshow(\"webcam\", img)\n",
    "    cv.imshow(\"face attendance\", imgBackground)\n",
    "    \n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break \n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'PIL.Image' has no attribute 'ANTIALIAS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mkuliah\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFC\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your actual folder path\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Resize images with a new width of 400 pixels (adjust as needed)\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[43mresize_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m216\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m216\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 13\u001b[0m, in \u001b[0;36mresize_images\u001b[1;34m(folder_path, new_width, new_height)\u001b[0m\n\u001b[0;32m     11\u001b[0m width, height \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39msize\n\u001b[0;32m     12\u001b[0m new_height \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(height \u001b[38;5;241m*\u001b[39m new_width \u001b[38;5;241m/\u001b[39m width)\n\u001b[1;32m---> 13\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mresize((new_width, new_height), \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mANTIALIAS\u001b[49m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Save resized image with \"resized_\" prefix\u001b[39;00m\n\u001b[0;32m     15\u001b[0m img\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresized_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'PIL.Image' has no attribute 'ANTIALIAS'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def resize_images(folder_path, new_width=216, new_height = 216):\n",
    "    \"\"\"Resizes all images in the specified folder to the given width.\"\"\"\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            img = Image.open(os.path.join(folder_path, filename))\n",
    "            # Resize image while maintaining aspect ratio\n",
    "            width, height = img.size\n",
    "            new_height = int(height * new_width / width)\n",
    "            img = img.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "            # Save resized image with \"resized_\" prefix\n",
    "            img.save(os.path.join(folder_path, f\"resized_{filename}\"))\n",
    "            print(f\"Resized: {filename}\")\n",
    "\n",
    "# Specify the folder path containing images\n",
    "folder_path = \"D:\\kuliah\\FC\\images\"  # Replace with your actual folder path\n",
    "\n",
    "# Resize images with a new width of 400 pixels (adjust as needed)\n",
    "resize_images(folder_path, new_width=216, new_height=216)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import cvzone as cvz\n",
    "import face_recognition\n",
    "from datetime import datetime\n",
    "\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, db\n",
    "from firebase_admin import storage\n",
    "cred = credentials.Certificate('D:\\kuliah\\FC\\others\\serviceAccountKey.json')\n",
    "firebase_admin.initialize_app(cred,{\n",
    "'databaseURL':\"https://fv-project-81f32-default-rtdb.firebaseio.com/\",\n",
    "'storageBucket':\"fv-project-81f32.appspot.com\"\n",
    "})\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "cap.set(cv.CAP_PROP_FPS, 45)\n",
    "\n",
    "imgBackground = cv.imread('resource/background.png')\n",
    "\n",
    "folderMode = 'resource/Modes'\n",
    "modePath = os.listdir(folderMode)\n",
    "imgModeList = []\n",
    "for path in modePath:\n",
    "    imgModeList.append(cv.imread(os.path.join(folderMode, path)))\n",
    "# print(len(imgModeList))\n",
    "\n",
    "FaceDist = None\n",
    "match = None\n",
    "\n",
    "#load encoder\n",
    "print(\"loading encoder\")\n",
    "file = open('encodefile.p', 'rb')\n",
    "knownEncodeID = pickle.load(file)\n",
    "file.close()\n",
    "knownEncode, stdID = knownEncodeID\n",
    "# print(stdID)\n",
    "print(\"encoder loaded\")\n",
    "\n",
    "modeType = 0\n",
    "counter = 0\n",
    "id = -1\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    imgS = cv.resize(img,(0, 0), None, 0.25, 0.25,)\n",
    "    imgS = cv.cvtColor(imgS, cv.COLOR_BGR2RGB)\n",
    "    \n",
    "    faceCF = face_recognition.face_locations(imgS)\n",
    "    encodeCF = face_recognition.face_encodings(imgS, faceCF)\n",
    "    # print(faceCF)\n",
    "    # print(encodeCF)    \n",
    "    \n",
    "    imgBackground[162:162+480, 55:55+640] = img\n",
    "    imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "        \n",
    "    for encodeFace, faceLoc in zip(encodeCF, faceCF):\n",
    "        # print(faceLoc)\n",
    "        match = face_recognition.compare_faces(knownEncode, encodeFace)\n",
    "        FaceDist = face_recognition.face_distance(knownEncode, encodeFace)\n",
    "        # print('Loop iteration executed')\n",
    "        # print('matches:', match)\n",
    "        # print('faceDis:', faceDis)\n",
    "\n",
    "    matchedindex = np.argmin(FaceDist)\n",
    "    # print(\"match index : \", matchIndex)\n",
    "    \n",
    "    if encodeCF:  # Check if encodeCF is not empty\n",
    "        matchedIndex = np.argmin(FaceDist)\n",
    "        \n",
    "        if match[matchedIndex]:\n",
    "            # print(\"Known Face Detected\")\n",
    "            # print(stdID[matchedIndex])\n",
    "            time.sleep(1)\n",
    "            y1, x2, y2, x1 = faceLoc\n",
    "            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "            bbox = 55 + x1, 162 + y1, x2 - x1, y2 - y1\n",
    "            imgBackground = cvz.cornerRect(imgBackground, bbox, rt=0)\n",
    "                        \n",
    "            id = stdID[matchedIndex]\n",
    "            # print(id)            \n",
    "            if counter == 0:\n",
    "                counter = 1\n",
    "                modeType = 1\n",
    "    if counter!= 0:\n",
    "        if counter == 1:\n",
    "            stdInfo = db.reference(f'Mahasiswa/{id}').get()\n",
    "            print(stdInfo)\n",
    "            \n",
    "            #update attendance\n",
    "            datetimeObject = datetime.strptime(stdInfo['lastAttendance_Time'],\n",
    "                                                   \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            secondsElapsed = (datetime.now()-datetimeObject).total_seconds()\n",
    "            print(secondsElapsed)\n",
    "            if secondsElapsed > 30:\n",
    "                ref = db.reference(f'Mahasiswa/{id}')\n",
    "                stdInfo['total_attendance'] +=1\n",
    "                ref.child('total_attendance').set(stdInfo['total_attendance'])\n",
    "                ref.child('lastAttendance_Time').set(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "            else :\n",
    "                modeType = 3\n",
    "                counter = 0\n",
    "                imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "                \n",
    "        if modeType != 3:\n",
    "            \n",
    "    \n",
    "            if 10<counter<20:\n",
    "                modeType = 2\n",
    "                imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "            \n",
    "            if counter <= 10:\n",
    "                        \n",
    "                cv.putText(imgBackground, str(stdInfo['total_attendance']), (861, 125),\n",
    "                            cv.FONT_HERSHEY_COMPLEX, 1, (0, 0, 0), 1)\n",
    "                (w, h), _ = cv.getTextSize(stdInfo['Nama'], cv.FONT_HERSHEY_COMPLEX, 1, 1)\n",
    "                cv.putText(imgBackground, str(stdInfo['Nama']), (922, 445),\n",
    "                            cv.FONT_HERSHEY_COMPLEX, 0.5, (50, 50, 50), 1)\n",
    "                cv.putText(imgBackground, str(stdInfo['Jurusan']), (835, 550),\n",
    "                            cv.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0), 1)# background, info, koordinat, font, ukuran, warna, tebal\n",
    "                cv.putText(imgBackground, str(id), (950, 493),\n",
    "                            cv.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0), 1)\n",
    "            \n",
    "    counter+=1\n",
    "    \n",
    "    if counter > 20:\n",
    "        counter = 0\n",
    "        modeType = 0\n",
    "        stdInfo = []\n",
    "        \n",
    "        imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "\n",
    "    # cv.imshow(\"webcam\", img)\n",
    "    cv.imshow(\"face attendance\", imgBackground)\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break \n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BG NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import cvzone as cvz\n",
    "import face_recognition\n",
    "from datetime import datetime\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "cap.set(cv.CAP_PROP_FPS, 45)\n",
    "\n",
    "folderMode = 'resource/ModesNew'\n",
    "modePath = os.listdir(folderMode)\n",
    "imgModeList = []\n",
    "for path in modePath:\n",
    "    imgModeList.append(cv.imread(os.path.join(folderMode, path)))\n",
    "# print(len(imgModeList))\n",
    "\n",
    "modeType = 0\n",
    "counter = 0\n",
    "id = -1\n",
    "\n",
    "imgBackground = cv.imread('resource/bg.jpeg')\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        print(\"Error: Unable to read frame.\")\n",
    "        break\n",
    "    \n",
    "    # Resize the frame\n",
    "    # imgS = cv.resize(img, (0, 0), None, 0.7, 0.7)  # Resize by 0.25 (quarter of original size)\n",
    "    new_width = int(0.7 * img.shape[1])\n",
    "    new_height = int(0.7 * img.shape[0])\n",
    "    imgS = cv.resize(img, (new_width, new_height))    \n",
    "    # Convert color from BGR to RGB\n",
    "    imgS = cv.cvtColor(imgS, cv.COLOR_BGR2RGB)\n",
    "    \n",
    "    faceCF = face_recognition.face_locations(imgS)\n",
    "    encodeCF = face_recognition.face_encodings(imgS, faceCF)\n",
    "    \n",
    "    imgBackground[200:200+imgS.shape[0], 50:50+imgS.shape[1]] = imgS\n",
    "    \n",
    "\n",
    "    # Resize the image back to its original size\n",
    "    resized_width = int(1.0 *587)\n",
    "    resized_height = int(1.3 * 174)\n",
    "    imgModeResized = cv.resize(imgModeList[modeType], (resized_width, resized_height))\n",
    "\n",
    "    # Assign the resized image to the specified region in imgBackground\n",
    "    imgBackground[305:305 + imgModeResized.shape[0], 539:539 + imgModeResized.shape[1]] = imgModeResized\n",
    "\n",
    "    \n",
    "    \n",
    "    # Display the frame with the overlay\n",
    "    cv.imshow(\"Face Attendance\", imgBackground)\n",
    "    \n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break \n",
    "\n",
    "# Release the camera and close all OpenCV windows\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manin.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import face_recognition\n",
    "import cvzone\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import db\n",
    "from firebase_admin import storage\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "cred = credentials.Certificate(\"serviceAccountKey.json\")\n",
    "firebase_admin.initialize_app(cred, {\n",
    "    'databaseURL': \"\",\n",
    "    'storageBucket': \"\"\n",
    "})\n",
    "\n",
    "bucket = storage.bucket()\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "imgBackground = cv2.imread('Resources/background.png')\n",
    "\n",
    "# Importing the mode images into a list\n",
    "folderModePath = 'Resources/Modes'\n",
    "modePathList = os.listdir(folderModePath)\n",
    "imgModeList = []\n",
    "for path in modePathList:\n",
    "    imgModeList.append(cv2.imread(os.path.join(folderModePath, path)))\n",
    "# print(len(imgModeList))\n",
    "\n",
    "# Load the encoding file\n",
    "print(\"Loading Encode File ...\")\n",
    "file = open('EncodeFile.p', 'rb')\n",
    "encodeListKnownWithIds = pickle.load(file)\n",
    "file.close()\n",
    "encodeListKnown, studentIds = encodeListKnownWithIds\n",
    "# print(studentIds)\n",
    "print(\"Encode File Loaded\")\n",
    "\n",
    "modeType = 0\n",
    "counter = 0\n",
    "id = -1\n",
    "imgStudent = []\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "\n",
    "    imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    faceCurFrame = face_recognition.face_locations(imgS)\n",
    "    encodeCurFrame = face_recognition.face_encodings(imgS, faceCurFrame)\n",
    "\n",
    "    imgBackground[162:162 + 480, 55:55 + 640] = img\n",
    "    imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "\n",
    "    if faceCurFrame:\n",
    "        for encodeFace, faceLoc in zip(encodeCurFrame, faceCurFrame):\n",
    "            matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
    "            faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
    "            # print(\"matches\", matches)\n",
    "            # print(\"faceDis\", faceDis)\n",
    "\n",
    "            matchIndex = np.argmin(faceDis)\n",
    "            # print(\"Match Index\", matchIndex)\n",
    "\n",
    "            if matches[matchIndex]:\n",
    "                # print(\"Known Face Detected\")\n",
    "                # print(studentIds[matchIndex])\n",
    "                y1, x2, y2, x1 = faceLoc\n",
    "                y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "                bbox = 55 + x1, 162 + y1, x2 - x1, y2 - y1\n",
    "                imgBackground = cvzone.cornerRect(imgBackground, bbox, rt=0)\n",
    "                id = studentIds[matchIndex]\n",
    "                if counter == 0:\n",
    "                    cvzone.putTextRect(imgBackground, \"Loading\", (275, 400))\n",
    "                    cv2.imshow(\"Face Attendance\", imgBackground)\n",
    "                    cv2.waitKey(1)\n",
    "                    counter = 1\n",
    "                    modeType = 1\n",
    "\n",
    "        if counter != 0:\n",
    "\n",
    "            if counter == 1:\n",
    "                # Get the Data\n",
    "                studentInfo = db.reference(f'Students/{id}').get()\n",
    "                print(studentInfo)\n",
    "                # Get the Image from the storage\n",
    "                blob = bucket.get_blob(f'Images/{id}.png')\n",
    "                array = np.frombuffer(blob.download_as_string(), np.uint8)\n",
    "                imgStudent = cv2.imdecode(array, cv2.COLOR_BGRA2BGR)\n",
    "                # Update data of attendance\n",
    "                datetimeObject = datetime.strptime(studentInfo['last_attendance_time'],\n",
    "                                                   \"%Y-%m-%d %H:%M:%S\")\n",
    "                secondsElapsed = (datetime.now() - datetimeObject).total_seconds()\n",
    "                print(secondsElapsed)\n",
    "                if secondsElapsed > 30:\n",
    "                    ref = db.reference(f'Students/{id}')\n",
    "                    studentInfo['total_attendance'] += 1\n",
    "                    ref.child('total_attendance').set(studentInfo['total_attendance'])\n",
    "                    ref.child('last_attendance_time').set(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "                else:\n",
    "                    modeType = 3\n",
    "                    counter = 0\n",
    "                    imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "\n",
    "            if modeType != 3:\n",
    "\n",
    "                if 10 < counter < 20:\n",
    "                    modeType = 2\n",
    "\n",
    "                imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "\n",
    "                if counter <= 10:\n",
    "                    cv2.putText(imgBackground, str(studentInfo['total_attendance']), (861, 125),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 1)\n",
    "                    cv2.putText(imgBackground, str(studentInfo['major']), (1006, 550),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                    cv2.putText(imgBackground, str(id), (1006, 493),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                    cv2.putText(imgBackground, str(studentInfo['standing']), (910, 625),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 0.6, (100, 100, 100), 1)\n",
    "                    cv2.putText(imgBackground, str(studentInfo['year']), (1025, 625),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 0.6, (100, 100, 100), 1)\n",
    "                    cv2.putText(imgBackground, str(studentInfo['starting_year']), (1125, 625),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 0.6, (100, 100, 100), 1)\n",
    "\n",
    "                    (w, h), _ = cv2.getTextSize(studentInfo['name'], cv2.FONT_HERSHEY_COMPLEX, 1, 1)\n",
    "                    offset = (414 - w) // 2\n",
    "                    cv2.putText(imgBackground, str(studentInfo['name']), (808 + offset, 445),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 1, (50, 50, 50), 1)\n",
    "\n",
    "                    imgBackground[175:175 + 216, 909:909 + 216] = imgStudent\n",
    "\n",
    "                counter += 1\n",
    "\n",
    "                if counter >= 20:\n",
    "                    counter = 0\n",
    "                    modeType = 0\n",
    "                    studentInfo = []\n",
    "                    imgStudent = []\n",
    "                    imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "    else:\n",
    "        modeType = 0\n",
    "        counter = 0\n",
    "    # cv2.imshow(\"Webcam\", img)\n",
    "    cv2.imshow(\"Face Attendance\", imgBackground)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import cvzone as cvz\n",
    "import face_recognition\n",
    "from datetime import datetime\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, db\n",
    "from firebase_admin import storage\n",
    "cred = credentials.Certificate('D:\\kuliah\\FC\\others\\serviceAccountKey.json')\n",
    "firebase_admin.initialize_app(cred,{\n",
    "'databaseURL': \"https://fv-project-81f32-default-rtdb.firebaseio.com/\",\n",
    "'storageBucket':\"fv-project-81f32.appspot.com\"\n",
    "})\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "cap.set(cv.CAP_PROP_FPS, 45)\n",
    "\n",
    "imgBackground = cv.imread('resource/bg.jpeg')\n",
    "\n",
    "folderMode = 'resource/Modes'\n",
    "modePath = os.listdir(folderMode)\n",
    "imgModeList = []\n",
    "for path in modePath:\n",
    "    imgModeList.append(cv.imread(os.path.join(folderMode, path)))\n",
    "# print(len(imgModeList))\n",
    "\n",
    "FaceDist = None\n",
    "match = None\n",
    "\n",
    "#load encoder\n",
    "print(\"loading encoder\")\n",
    "file = open('encodefile.p', 'rb')\n",
    "knownEncodeID = pickle.load(file)\n",
    "file.close()\n",
    "knownEncode, stdID = knownEncodeID\n",
    "# print(stdID)\n",
    "print(\"encoder loaded\")\n",
    "\n",
    "modeType = 0\n",
    "counter = 0\n",
    "id = -1\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    #camera    \n",
    "    new_width = int(0.7 * img.shape[1])\n",
    "    new_height = int(0.7 * img.shape[0])\n",
    "    imgS = cv.resize(img, (new_width, new_height))    \n",
    "    imgS = cv.cvtColor(imgS, cv.COLOR_BGR2RGB)\n",
    "\n",
    "    faceCF = face_recognition.face_locations(imgS)\n",
    "    encodeCF = face_recognition.face_encodings(imgS, faceCF)\n",
    "    \n",
    "    imgBackground[200:200+imgS.shape[0], 50:50+imgS.shape[1]] = imgS\n",
    "\n",
    "    #status\n",
    "    resized_width = int(1.0 *587)\n",
    "    resized_height = int(1.3 * 174)\n",
    "    imgModeResized = cv.resize(imgModeList[modeType], (resized_width, resized_height))\n",
    "    # print(modeType)\n",
    "\n",
    "    # Assign the resized image to the specified region in imgBackground\n",
    "    imgBackground[305:305 + imgModeResized.shape[0], 539:539 + imgModeResized.shape[1]] = imgModeResized\n",
    "\n",
    "    for encodeFace, faceLoc in zip(encodeCF, faceCF):\n",
    "        # print(faceLoc)\n",
    "        match = face_recognition.compare_faces(knownEncode, encodeFace)\n",
    "        FaceDist = face_recognition.face_distance(knownEncode, encodeFace)\n",
    "        # print('Loop iteration executed')\n",
    "        # print('matches:', match)\n",
    "        # print('faceDis:', faceDis)\n",
    "\n",
    "    matchedindex = np.argmin(FaceDist)\n",
    "    # print(\"match index : \", matchIndex)\n",
    "    \n",
    "    if encodeCF:  # Check if encodeCF is not empty\n",
    "        matchedIndex = np.argmin(FaceDist)\n",
    "        \n",
    "        # if match[matchedIndex]:\n",
    "        #     # print(\"Known Face Detected\")\n",
    "        #     # print(stdID[matchedIndex])\n",
    "        #     time.sleep(1)\n",
    "        #     y1, x2, y2, x1 = faceLoc\n",
    "        #     y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "        #     bbox = 55 + x1, 162 + y1, x2 - x1, y2 - y1\n",
    "        #     imgBackground = cvz.cornerRect(imgBackground, bbox, rt=0)\n",
    "                        \n",
    "        #     id = stdID[matchedIndex]\n",
    "        #     # print(id)            \n",
    "        #     if counter == 0:\n",
    "        #         counter = 1\n",
    "        #         modeType = 1\n",
    "    if counter!= 0:\n",
    "        if counter == 1:\n",
    "            stdInfo = db.reference(f'Mahasiswa/{id}').get()\n",
    "            print(stdInfo)\n",
    "            \n",
    "            #update attendance\n",
    "            datetimeObject = datetime.strptime(stdInfo['last_Attendance_Time'],\n",
    "                                                \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            secondsElapsed = (datetime.now()-datetimeObject).total_seconds()\n",
    "            print(secondsElapsed)\n",
    "            if secondsElapsed > 30:\n",
    "                ref = db.reference(f'Mahasiswa/{id}')\n",
    "                stdInfo['total_attendance'] +=1\n",
    "                ref.child('total_attendance').set(stdInfo['total_attendance'])\n",
    "                ref.child('last_Attendance_Time').set(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "            else :\n",
    "                modeType = 3\n",
    "                counter = 0\n",
    "                imgBackground[305:305 + imgModeResized.shape[0], 539:539 + imgModeResized.shape[1]] = imgModeResized\n",
    "                \n",
    "        if modeType != 3:\n",
    "            \n",
    "    \n",
    "            if 10<counter<20:\n",
    "                modeType = 2\n",
    "                imgBackground[305:305 + imgModeResized.shape[0], 539:539 + imgModeResized.shape[1]] = imgModeResized\n",
    "\n",
    "            \n",
    "            if counter <= 10:\n",
    "                        \n",
    "                cv.putText(imgBackground, str(stdInfo['total_attendance']), (861, 125),\n",
    "                            cv.FONT_HERSHEY_COMPLEX, 1, (0, 0, 0), 1)\n",
    "                (w, h), _ = cv.getTextSize(stdInfo['Nama'], cv.FONT_HERSHEY_COMPLEX, 1, 1)\n",
    "                cv.putText(imgBackground, str(stdInfo['Nama']), (922, 445),\n",
    "                            cv.FONT_HERSHEY_COMPLEX, 0.5, (50, 50, 50), 1)\n",
    "                cv.putText(imgBackground, str(stdInfo['Jurusan']), (835, 550),\n",
    "                            cv.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0), 1)# background, info, koordinat, font, ukuran, warna, tebal\n",
    "                cv.putText(imgBackground, str(id), (950, 493),\n",
    "                            cv.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0), 1)\n",
    "            \n",
    "    counter+=1\n",
    "    \n",
    "    if counter > 20:\n",
    "        counter = 0\n",
    "        modeType = 0\n",
    "        stdInfo = []\n",
    "        \n",
    "        imgBackground[305:305 + imgModeResized.shape[0], 539:539 + imgModeResized.shape[1]] = imgModeResized\n",
    "\n",
    "    # cv.imshow(\"webcam\", img)\n",
    "    cv.imshow(\"face attendance\", imgBackground)\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break \n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import cvzone as cvz\n",
    "import face_recognition\n",
    "from datetime import datetime\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, db\n",
    "from firebase_admin import storage\n",
    "cred = credentials.Certificate('D:\\kuliah\\FC\\others\\serviceAccountKey.json')\n",
    "firebase_admin.initialize_app(cred,{\n",
    "'databaseURL': \"https://fv-project-81f32-default-rtdb.firebaseio.com/\",\n",
    "'storageBucket':\"fv-project-81f32.appspot.com\"\n",
    "})\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "cap.set(cv.CAP_PROP_FPS, 45)\n",
    "\n",
    "imgBackground = cv.imread('resource/background.png')\n",
    "\n",
    "folderMode = 'resource/Modes'\n",
    "modePath = os.listdir(folderMode)\n",
    "imgModeList = []\n",
    "for path in modePath:\n",
    "    imgModeList.append(cv.imread(os.path.join(folderMode, path)))\n",
    "# print(len(imgModeList))\n",
    "\n",
    "FaceDist = None\n",
    "match = None\n",
    "\n",
    "#load encoder\n",
    "print(\"loading encoder\")\n",
    "file = open('encodefile.p', 'rb')\n",
    "knownEncodeID = pickle.load(file)\n",
    "file.close()\n",
    "knownEncode, stdID = knownEncodeID\n",
    "# print(stdID)\n",
    "print(\"encoder loaded\")\n",
    "\n",
    "modeType = 0\n",
    "counter = 0\n",
    "id = -1\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    imgS = cv.resize(img,(0, 0), None, 0.25, 0.25,)\n",
    "    imgS = cv.cvtColor(imgS, cv.COLOR_BGR2RGB)\n",
    "    \n",
    "    faceCF = face_recognition.face_locations(imgS)\n",
    "    encodeCF = face_recognition.face_encodings(imgS, faceCF)\n",
    "    # print(faceCF)\n",
    "    # print(encodeCF)    \n",
    "    \n",
    "    imgBackground[162:162+480, 55:55+640] = img\n",
    "    imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "        \n",
    "    for encodeFace, faceLoc in zip(encodeCF, faceCF):\n",
    "        # print(faceLoc)\n",
    "        match = face_recognition.compare_faces(knownEncode, encodeFace)\n",
    "        FaceDist = face_recognition.face_distance(knownEncode, encodeFace)\n",
    "        # print('Loop iteration executed')\n",
    "        # print('matches:', match)\n",
    "        # print('faceDis:', faceDis)\n",
    "\n",
    "    matchedindex = np.argmin(FaceDist)\n",
    "    # print(\"match index : \", matchIndex)\n",
    "    \n",
    "    if encodeCF:  # Check if encodeCF is not empty\n",
    "        matchedIndex = np.argmin(FaceDist)\n",
    "        \n",
    "        if match[matchedIndex]:\n",
    "            # print(\"Known Face Detected\")\n",
    "            # print(stdID[matchedIndex])\n",
    "            time.sleep(1)\n",
    "            y1, x2, y2, x1 = faceLoc\n",
    "            y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "            bbox = 55 + x1, 162 + y1, x2 - x1, y2 - y1\n",
    "            imgBackground = cvz.cornerRect(imgBackground, bbox, rt=0)\n",
    "                        \n",
    "            id = stdID[matchedIndex]\n",
    "            # print(id)            \n",
    "            if counter == 0:\n",
    "                counter = 1\n",
    "                modeType = 1\n",
    "    if counter!= 0:\n",
    "        if counter == 1:\n",
    "            stdInfo = db.reference(f'Mahasiswa/{id}').get()\n",
    "            print(stdInfo)\n",
    "            \n",
    "            #update attendance\n",
    "            datetimeObject = datetime.strptime(stdInfo['last_Attendance_Time'],\n",
    "                                                \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            secondsElapsed = (datetime.now()-datetimeObject).total_seconds()\n",
    "            print(secondsElapsed)\n",
    "            if secondsElapsed > 30:\n",
    "                ref = db.reference(f'Mahasiswa/{id}')\n",
    "                stdInfo['total_attendance'] +=1\n",
    "                ref.child('total_attendance').set(stdInfo['total_attendance'])\n",
    "                ref.child('last_Attendance_Time').set(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "            else :\n",
    "                modeType = 3\n",
    "                counter = 0\n",
    "                imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "                \n",
    "        if modeType != 3:\n",
    "            \n",
    "    \n",
    "            if 10<counter<20:\n",
    "                modeType = 2\n",
    "                imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "            \n",
    "            if counter <= 10:\n",
    "                        \n",
    "                cv.putText(imgBackground, str(stdInfo['total_attendance']), (861, 125),\n",
    "                            cv.FONT_HERSHEY_COMPLEX, 1, (0, 0, 0), 1)\n",
    "                (w, h), _ = cv.getTextSize(stdInfo['Nama'], cv.FONT_HERSHEY_COMPLEX, 1, 1)\n",
    "                cv.putText(imgBackground, str(stdInfo['Nama']), (922, 445),\n",
    "                            cv.FONT_HERSHEY_COMPLEX, 0.5, (50, 50, 50), 1)\n",
    "                cv.putText(imgBackground, str(stdInfo['Jurusan']), (835, 550),\n",
    "                            cv.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0), 1)# background, info, koordinat, font, ukuran, warna, tebal\n",
    "                cv.putText(imgBackground, str(id), (950, 493),\n",
    "                            cv.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0), 1)\n",
    "            \n",
    "    counter+=1\n",
    "    \n",
    "    if counter > 20:\n",
    "        counter = 0\n",
    "        modeType = 0\n",
    "        stdInfo = []\n",
    "        \n",
    "        imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "\n",
    "    # cv.imshow(\"webcam\", img)\n",
    "    cv.imshow(\"face attendance\", imgBackground)\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break \n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
